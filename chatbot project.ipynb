{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd82273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! I am an NLP chatbot. Type 'bye' to exit.\n",
      "You: \"Hello\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How can I assist you today?\n",
      "You: \"What is machine learning?\"\n",
      "Chatbot: Machine learning refers to algorithms that improve based on experience or data.\n",
      "You: \"What is natural language?\"\n",
      "Chatbot: Natural language processing, or NLP, is a branch of AI that deals with the interaction between computers and humans through language.\n",
      "You: \"What is dep learning?\"\n",
      "Chatbot: Machine learning refers to algorithms that improve based on experience or data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string  # to process standard python strings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Downloading necessary nltk packages (first-time only)\n",
    "nltk.download('punkt')  # for tokenization\n",
    "nltk.download('wordnet')  # for lemmatization\n",
    "\n",
    "# Example corpus for chatbot (FAQs)\n",
    "faq_corpus = [\n",
    "    \"Hello, how can I help you?\",\n",
    "    \"Hi there, how can I assist?\",\n",
    "    \"What is natural language processing?\",\n",
    "    \"NLP is a field of AI that gives machines the ability to read, understand, and derive meaning from human language.\",\n",
    "    \"What is machine learning?\",\n",
    "    \"Machine learning is the study of computer algorithms that improve automatically through experience.\",\n",
    "    \"How does deep learning work?\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with many layers (deep architectures).\",\n",
    "    \"Who created you?\",\n",
    "    \"I was created by a team of AI enthusiasts.\",\n",
    "    \"Thank you!\",\n",
    "    \"You're welcome!\",\n",
    "    \"Goodbye!\"\n",
    "]\n",
    "\n",
    "faq_responses = [\n",
    "    \"Hello! How can I assist you today?\",\n",
    "    \"Hi! What can I do for you?\",\n",
    "    \"Natural language processing, or NLP, is a branch of AI that deals with the interaction between computers and humans through language.\",\n",
    "    \"NLP involves enabling computers to understand and respond to human language, helping in tasks such as translation, summarization, and conversation.\",\n",
    "    \"Machine learning refers to algorithms that improve based on experience or data.\",\n",
    "    \"Machine learning is about creating models that allow computers to learn patterns from data and make decisions or predictions.\",\n",
    "    \"Deep learning involves neural networks with multiple layers, often used for complex tasks such as image recognition, language translation, and more.\",\n",
    "    \"I was created using Python, machine learning, and some good old-fashioned programming.\",\n",
    "    \"I'm glad I could help! Anything else?\",\n",
    "    \"You're very welcome!\",\n",
    "    \"Goodbye! Feel free to come back if you need more help!\"\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "# Lemmatization\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "# Greeting responses\n",
    "greeting_inputs = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
    "greeting_responses = [\"Hello\", \"Hi\", \"Greetings!\", \"Hey there!\", \"Hello! How can I assist you today?\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    \"\"\"Return a greeting response if the user's input is a greeting.\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)\n",
    "\n",
    "# Generate response based on similarity\n",
    "def generate_response(user_input):\n",
    "    bot_response = ''\n",
    "    faq_corpus.append(user_input)  # Add user input to the corpus for similarity checking\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(faq_corpus)\n",
    "    \n",
    "    # Compute similarity between user input and corpus\n",
    "    similarity_values = cosine_similarity(tfidf_matrix[-1], tfidf_matrix)\n",
    "    index = similarity_values.argsort()[0][-2]  # Get the most similar response\n",
    "    flat = similarity_values.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    \n",
    "    if req_tfidf == 0:\n",
    "        bot_response = \"I am sorry, I don't understand. Could you rephrase that?\"\n",
    "    else:\n",
    "        bot_response = faq_responses[index]\n",
    "    \n",
    "    faq_corpus.pop()  # Remove user input from the corpus\n",
    "    return bot_response\n",
    "\n",
    "# Main chatbot interaction loop\n",
    "def chatbot():\n",
    "    print(\"Chatbot: Hello! I am an NLP chatbot. Type 'bye' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \").lower()\n",
    "        if user_input == 'bye':\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            if greeting(user_input) is not None:\n",
    "                print(f\"Chatbot: {greeting(user_input)}\")\n",
    "            else:\n",
    "                print(f\"Chatbot: {generate_response(user_input)}\")\n",
    "\n",
    "# Run the chatbot\n",
    "chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f4ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
